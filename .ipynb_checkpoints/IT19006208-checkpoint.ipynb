{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911068ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f82bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52ca3da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                          0           0  \n",
       "1                          3           1  \n",
       "2                          2           0  \n",
       "3                          5           1  \n",
       "4                          2           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/SeliyaMindula/ML_Assignment2_IT19151298_IT19149936_IT19006208_IT19179186/IT19006208-Ranathunga_J.K/Dataset/Employee.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4bf7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Number of Rows, Colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022ad6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4653 entries, 0 to 4652\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Education                  4653 non-null   object\n",
      " 1   JoiningYear                4653 non-null   int64 \n",
      " 2   City                       4653 non-null   object\n",
      " 3   PaymentTier                4653 non-null   int64 \n",
      " 4   Age                        4653 non-null   int64 \n",
      " 5   Gender                     4653 non-null   object\n",
      " 6   EverBenched                4653 non-null   object\n",
      " 7   ExperienceInCurrentDomain  4653 non-null   int64 \n",
      " 8   LeaveOrNot                 4653 non-null   int64 \n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 327.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c524e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Missing Values in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8028e3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education                    0\n",
       "JoiningYear                  0\n",
       "City                         0\n",
       "PaymentTier                  0\n",
       "Age                          0\n",
       "Gender                       0\n",
       "EverBenched                  0\n",
       "ExperienceInCurrentDomain    0\n",
       "LeaveOrNot                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea55a41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4653, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410d2b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bachelors    3601\n",
       "Masters       873\n",
       "PHD           179\n",
       "Name: Education, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa9c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gender_convert(inp):\n",
    "    if inp=='Male':\n",
    "        return '0'\n",
    "    if inp=='Female':\n",
    "        return '1'\n",
    "data['Gender']= data['Gender'].apply(Gender_convert) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f7068ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4648    1\n",
       "4649    0\n",
       "4650    0\n",
       "4651    0\n",
       "4652    0\n",
       "Name: Gender, Length: 4653, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193afcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'] = pd.to_numeric(data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7e6cc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "4648    1\n",
       "4649    0\n",
       "4650    0\n",
       "4651    0\n",
       "4652    0\n",
       "Name: Gender, Length: 4653, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45cd3c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bachelors\n",
       "1       Bachelors\n",
       "2       Bachelors\n",
       "3         Masters\n",
       "4         Masters\n",
       "          ...    \n",
       "4648    Bachelors\n",
       "4649      Masters\n",
       "4650      Masters\n",
       "4651    Bachelors\n",
       "4652    Bachelors\n",
       "Name: Education, Length: 4653, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79ccfe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Education_convert(inp):\n",
    "    if inp=='Bachelors':\n",
    "        return '0'\n",
    "    if inp=='Masters':\n",
    "        return '1'\n",
    "    if inp=='PHD':\n",
    "        return '2'\n",
    "data['Education']= data['Education'].apply(Education_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfc024ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "4648    0\n",
       "4649    1\n",
       "4650    1\n",
       "4651    0\n",
       "4652    0\n",
       "Name: Education, Length: 4653, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c305e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Education'] = pd.to_numeric(data['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfcaa675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "4648    0\n",
       "4649    1\n",
       "4650    1\n",
       "4651    0\n",
       "4652    0\n",
       "Name: Education, Length: 4653, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e57e7b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bangalore\n",
       "1            Pune\n",
       "2       New Delhi\n",
       "3       Bangalore\n",
       "4            Pune\n",
       "          ...    \n",
       "4648    Bangalore\n",
       "4649         Pune\n",
       "4650    New Delhi\n",
       "4651    Bangalore\n",
       "4652    Bangalore\n",
       "Name: City, Length: 4653, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd00c1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bangalore    2228\n",
       "Pune         1268\n",
       "New Delhi    1157\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c35920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def City_convert(inp):\n",
    "    if inp=='Bangalore':\n",
    "        return '0'\n",
    "    if inp=='Pune':\n",
    "        return '1'\n",
    "    if inp=='New Delhi':\n",
    "        return '2'\n",
    "data['City']= data['City'].apply(City_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9932e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City'] = pd.to_numeric(data['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "498b7fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       2\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "4648    0\n",
       "4649    1\n",
       "4650    2\n",
       "4651    0\n",
       "4652    0\n",
       "Name: City, Length: 4653, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb9b0011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     4175\n",
       "Yes     478\n",
       "Name: EverBenched, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data['EverBenched'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2f4a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EverBenched_convert(inp):\n",
    "    if inp=='No':\n",
    "        return '0'\n",
    "    if inp=='Yes':\n",
    "        return '1'\n",
    "data['EverBenched']= data['EverBenched'].apply(EverBenched_convert) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2abefcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['EverBenched'] = pd.to_numeric(data['EverBenched'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70cd9b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "4648    0\n",
       "4649    0\n",
       "4650    0\n",
       "4651    1\n",
       "4652    1\n",
       "Name: EverBenched, Length: 4653, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EverBenched']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5fcd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4653 entries, 0 to 4652\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   Education                  4653 non-null   int64\n",
      " 1   JoiningYear                4653 non-null   int64\n",
      " 2   City                       4653 non-null   int64\n",
      " 3   PaymentTier                4653 non-null   int64\n",
      " 4   Age                        4653 non-null   int64\n",
      " 5   Gender                     4653 non-null   int64\n",
      " 6   EverBenched                4653 non-null   int64\n",
      " 7   ExperienceInCurrentDomain  4653 non-null   int64\n",
      " 8   LeaveOrNot                 4653 non-null   int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 327.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00a9c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('LeaveOrNot',axis=1)\n",
    "Y = data['LeaveOrNot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e60908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education  JoiningYear  City  PaymentTier  Age  Gender  EverBenched  \\\n",
       "0             0         2017     0            3   34       0            0   \n",
       "1             0         2013     1            1   28       1            0   \n",
       "2             0         2014     2            3   38       1            0   \n",
       "3             1         2016     0            3   27       0            0   \n",
       "4             1         2017     1            3   24       0            1   \n",
       "...         ...          ...   ...          ...  ...     ...          ...   \n",
       "4648          0         2013     0            3   26       1            0   \n",
       "4649          1         2013     1            2   37       0            0   \n",
       "4650          1         2018     2            3   27       0            0   \n",
       "4651          0         2012     0            3   30       0            1   \n",
       "4652          0         2015     0            3   33       0            1   \n",
       "\n",
       "      ExperienceInCurrentDomain  \n",
       "0                             0  \n",
       "1                             3  \n",
       "2                             2  \n",
       "3                             5  \n",
       "4                             2  \n",
       "...                         ...  \n",
       "4648                          4  \n",
       "4649                          2  \n",
       "4650                          5  \n",
       "4651                          2  \n",
       "4652                          4  \n",
       "\n",
       "[4653 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61306d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "4648    0\n",
       "4649    1\n",
       "4650    1\n",
       "4651    0\n",
       "4652    0\n",
       "Name: LeaveOrNot, Length: 4653, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da46fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18d9efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_acc(model):\n",
    "    model.fit(X_train,Y_train)\n",
    "    acc1 = model.score(X_train,Y_train)\n",
    "    acc2 = model.score(X_test,Y_test)\n",
    "    print(str(model)+' Training Accuracy --> '+str(acc1))\n",
    "    print(str(model)+' Testing Accuracy --> '+str(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18a0d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB() Training Accuracy --> 0.6657710908113917\n",
      "GaussianNB() Testing Accuracy --> 0.6928034371643395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNBmodel = GaussianNB()\n",
    "model_acc(GNBmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf785236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() Training Accuracy --> 0.6448146157979581\n",
      "MultinomialNB() Testing Accuracy --> 0.6809881847475833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MNBmodel = MultinomialNB()\n",
    "model_acc(MNBmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d160f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier() Training Accuracy --> 0.35088662009672217\n",
      "SGDClassifier() Testing Accuracy --> 0.3157894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGDCmodel = SGDClassifier()\n",
    "model_acc(SGDCmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fc9deed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...) Training Accuracy --> 0.8933369156367544\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...) Testing Accuracy --> 0.8764769065520945\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "XGBmodel = XGBClassifier()\n",
    "model_acc(XGBmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e81ba569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[22:11:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"criterion\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              criterion='friedman_mse', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=10, max_bin=256,\n",
       "              max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'learning_rate' :[10, 50, 100],\n",
    "            'criterion' :['friedman_mse','squared_error','mse']}\n",
    "\n",
    "grid_obj = GridSearchCV(estimator=XGBmodel, param_grid=parameters)\n",
    "\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "best_model = grid_fit.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37316e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.719656283566058"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6ea3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('predictor.pickle', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb6da566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age', 'Gender',\n",
       "       'EverBenched', 'ExperienceInCurrentDomain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "895c8051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNBmodel.predict([[0,2017,0,3,34,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cdda4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() Training Accuracy --> 0.6800107469102633\n",
      "LogisticRegression() Testing Accuracy --> 0.7132116004296455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LRmodel = LogisticRegression()\n",
    "model_acc(LRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecf77eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() Training Accuracy --> 0.6491133799032778\n",
      "SVC() Testing Accuracy --> 0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVCmodel = SVC()\n",
    "model_acc(SVCmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f860119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB() Training Accuracy --> 0.6657710908113917\n",
      "GaussianNB() Testing Accuracy --> 0.6928034371643395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GAmodel = GaussianNB()\n",
    "model_acc(GAmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a21ca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier() Training Accuracy --> 0.6491133799032778\n",
      "SGDClassifier() Testing Accuracy --> 0.6842105263157895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGmodel = SGDClassifier()\n",
    "model_acc(SGmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfe0433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() Training Accuracy --> 0.831810854379366\n",
      "KNeighborsClassifier() Testing Accuracy --> 0.8184747583243824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNmodel = KNeighborsClassifier()\n",
    "model_acc(KNmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5640d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB() Training Accuracy --> 0.6448146157979581\n",
      "MultinomialNB() Testing Accuracy --> 0.6809881847475833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MUmodel = MultinomialNB()\n",
    "model_acc(MUmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2eef145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier() Training Accuracy --> 0.9279957012358947\n",
      "DecisionTreeClassifier() Testing Accuracy --> 0.8464017185821697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DEmodel = DecisionTreeClassifier()\n",
    "model_acc(DEmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87fcd4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier() Training Accuracy --> 0.9279957012358947\n",
      "RandomForestClassifier() Testing Accuracy --> 0.8603651987110634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RAmodel = RandomForestClassifier()\n",
    "model_acc(RAmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "624951eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier() Training Accuracy --> 0.8479312197743148\n",
      "GradientBoostingClassifier() Testing Accuracy --> 0.874328678839957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GRmodel = GradientBoostingClassifier()\n",
    "model_acc(GRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3708f529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...) Training Accuracy --> 0.8933369156367544\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...) Testing Accuracy --> 0.8764769065520945\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "XGmodel = XGBClassifier()\n",
    "model_acc(XGmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "910e35f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAmodel.predict([[0,2017,0,3,34,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cba6c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 898, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 347, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.81703832 0.81811034 0.81569423 0.81488923 0.81811215 0.81757451\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_estimators' :[10, 50, 100],\n",
    "            'criterion' :['gini','entropy','log_loss']}\n",
    "\n",
    "grid_obj = GridSearchCV(estimator=RAmodel, param_grid=parameters)\n",
    "\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "best_model = grid_fit.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d7875e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560687432867884"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe196e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('predictor.pickle', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09f3febb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict([[0,2017,0,3,34,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8eca11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
